---
title: "results"
author: "Elizabeth Williams"
date: "2024-07-23"
output: html_document
---

# Quantitative Literature Review on Forest Succession Post-Landslide Disturbance

## Load Packages

```{r load packages, message = FALSE}
library(revtools)
library(synthesisr)
library(dplyr)
library(janitor)
library(tidyverse)
library(stringr)
library(tidytext)
library(widyr)
library(ggraph)
library(ggplot2)
library(maps)
library(igraph)
library(base)
library(stm)
library(wordcloud)
library(sf) #vector package
library(terra) #raster package
library(ggbreak)
```

## Import data
```{r load data, message = FALSE}
#import metadata from read articles
metadata_record <- read.csv("data_working/metadata_R_input.csv")

#import WWF Biomes shapefile
biomes_shp <- st_read("data_external/wwf_terr_ecos/wwf_terr_ecos.shp")

#import world clim 2.1 solar radiation for Jan-Dec 1970-2000
srad_files <- list.files("data_external/wc2.1_30s_srad", pattern = "\\.tif", full.names = TRUE)
srad_raster <- rast(srad_files)

#import world clim 2.1 bio variables for Jan-Dec 1970-2000
bioclim_files <-list.files("data_external/wc2.1_30s_bio", pattern = "\\.tif", full.names = TRUE)
bioclim_raster <- rast(bioclim_files)

```

## Clean Biomes Data
```{r clean biomes data}
invalid_geometries <- !st_is_valid(biomes_shp)
if (any(invalid_geometries)) {
  # Print which features are invalid
  print(which(invalid_geometries))
}

# Fix invalid geometries
wwf_biomes <- st_make_valid(biomes_shp)

#Include biome names
biome_names <- c(
  "1" = "Tropical and subtropical moist broadleaf forests",
  "2" = "Tropical and subtropical dry broadleaf forests",
  "3" = "Tropical and subtropical coniferous forests",
  "4" = "Temperate broadleaf and mixed forests",
  "5" = "Temperate Coniferous Forest",
  "6" = "Boreal forests / Taiga",
  "7" = "Tropical and subtropical grasslands, savannas and shrublands",
  "8" = "Temperate grasslands, savannas and shrublands",
  "9" = "Flooded grasslands and savannas",
  "10" = "Montane grasslands and shrublands",
  "11" = "Tundra",
  "12" = "Mediterranean Forests, woodlands and scrubs",
  "13" = "Deserts and xeric shrublands",
  "14" = "Mangroves"
)

wwf_biomes <- wwf_biomes %>% 
  mutate(BIOME_NAME = biome_names[as.character(BIOME)])

```


## Sort data
```{r sort data, message = FALSE}
#remove articles not available for download
rm_download <- metadata_record %>%
  filter(grepl("TRUE", download, ignore.case = TRUE))

#remove articles not in english
rm_english <- rm_download %>%
  filter(grepl("TRUE", english, ignore.case = TRUE))

#remove all non-primary/not-peer-reviewed research
rm_article <- rm_english %>%
  filter(
    grepl ("FALSE", review, ignore.case = TRUE) &
       grepl ("FALSE", conference, ignore.case = TRUE) &
       grepl ("FALSE", report_other, ignore.case = TRUE)
    )

#remove all dendrogeomorph/disturbance history reconstruction
rm_dendrogeo <- rm_article %>%
  filter(grepl("FALSE", dendrogeo, ignore.case = TRUE))

#remove all listed as "reject_other"
sorted_data <- rm_dendrogeo %>%
  filter(grepl("FALSE", reject_other, ignore.case = TRUE))

#clean unnecessary columns
clean_data <- select(sorted_data, -c(database, document_type, language, volume, article_number, notes, source_type, issue, start_page, end_page, place_published, pi, we, cp, filename,
                                     n_duplicates, relevant_title, relevant_keyword, relevant, first_screening, screened_titles, second_screen, download, research_rabbit, english, 
                                     review, conference, report_other, dendrogeo, reject_other, coordinates, riparian))

```


## Extra sorting
```{r extra sorting, message = FALSE}
#isolate modelling papers
predict_model <- clean_data %>%
  filter(str_detect(study_method, "model") | str_detect(forecast_model, "TRUE"))

#isolate field & remote sensing papers
field_rs_data <- clean_data %>%
  filter(str_detect(study_method, "remote") | str_detect(study_method, "field"))

```


## add data from coordinates
```{r add data from coordinates, message = FALSE}
# clean coordinates
field_rs_data <- field_rs_data %>%
  separate(approx_coord, into = c("lat", "long"), sep = ", ", convert = TRUE)

coord_sf <- st_as_sf(field_rs_data, coords = c("long", "lat"), crs = 4326)


#extract worldclim 2.1 data from coordinates
clim_value <- extract(bioclim_raster, coord_sf, method = "simple")

srad_value <- extract(srad_raster, coord_sf, method = "simple")

srad_value <- srad_value %>%
  mutate(srad_avg = rowMeans(select(.,2:13), na.rm = TRUE))

field_rs_data <- cbind(field_rs_data, clim_value[,-1]) #exclude 1 - ID column
field_rs_data$srad_avg <- srad_value$srad_avg

#extract wwf biomes data from coordinates
biome_value <- st_join(coord_sf, wwf_biomes, join = st_intersects)

field_rs_data$biome <- biome_value$BIOME
field_rs_data$biome_name <-biome_value$BIOME_NAME
field_rs_data$eco_name <- biome_value$ECO_NAME

```


```{r spatsample random 1000 bioclim points, message = FALSE}

# Generate random control points and convert to df
clim_ctrl_points <- spatSample(bioclim_raster, size = 1000, na.rm = TRUE, as.points = TRUE)
clim_ctrl_data <- data.frame(crds(clim_ctrl_points))

# Extract worldclim 2.1 data from coordinates
clim_ctrl_value <- extract(bioclim_raster, clim_ctrl_points, method = "simple")

clim_ctrl_data <- cbind(clim_ctrl_data, clim_ctrl_value[,-1]) #exclude 1 - ID column

```


## Seperate field & remote sensing studies
```{r split field & rs data, message = FALSE}
#split field papers
field_data <- field_rs_data %>%
  filter(str_detect(study_method, "field"))

#split remote sensing papers
rs_data <- field_rs_data %>%
  filter(str_detect(study_method, "remote"))

```


## Maps of research
```{r research map}
# intensity map of countries of all studies
countries_split <- clean_data %>%
  separate_rows(country, sep = ", ") %>%
  mutate(country = case_when(
    country == "scotland" ~ "uk",
    country == "england" ~ "uk",
    country == "united states" ~ "usa",
    TRUE ~ country
  ))
  
country_counts <- countries_split %>%
  count(country, name = "papers")

world_map <- map_data("world")
world_map$region <- tolower(world_map$region)

map_data <- world_map %>%
  left_join(country_counts, by = c("region" = "country"))

ggplot(map_data, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = papers), color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue", na.value = "gray") +
  theme_minimal() +
  labs(title = "Color Intensity Map Based on Frequency of Studies",
       fill = "Papers")


# dot map of all field & RS studies
ggplot() +
  borders("world", colour = "gray85", fill = "gray80") +  # Plot the world map
  geom_point(data = field_rs_data, aes(x = long, y = lat, colour = study_method), size = 1) +  # Add points
  scale_color_manual(values = c("field" = "red", "remote sensing" = "blue")) + #Set colors
  theme_minimal() +
  labs(title = "Distribution of Field & Remote Sensing Research",
       x = "Longitude",
       y = "Latitude",
       colour = "Primary Research Method")

# Focus on SE Asia
ggplot() +
  borders("world", colour = "gray85", fill = "gray80") +  # Plot the world map
  geom_point(data = field_rs_data, aes(x = long, y = lat, colour = study_method), size = 1.5) +  # Add points
  scale_color_manual(values = c("field" = "red", "remote sensing" = "blue")) + #Set colors
  coord_cartesian(xlim = c(70, 150), ylim = c(10, 50)) +  # Zoom in on the specified region
  theme_minimal() +
  labs(title = "Distribution of Field & Remote Sensing Research (SE Asia)",
       x = "Longitude",
       y = "Latitude",
       color = "Primary Research Method")

```

## Papers over time
```{r papers over time}
# ALL PAPERS

years_all <- data.frame(year = seq(1964, 2024))

years_papers <- clean_data %>%
  count(year, name = "count") %>%
  right_join(years_all, by = "year") %>%
  replace_na(list(count = 0)) %>%
  filter(year <= 2023)
  
ggplot(years_papers, aes(x = year, y = count)) +
  geom_line() +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  scale_x_continuous(breaks = seq(1970, max(years_rs_field$year), by = 10)) +
  labs(title = "All Papers Published per Year",
       x = "Year",
       y = "Number of Studies Published") +
  theme_minimal()


# REMOTE SENSING & FIELD PAPERS

years_rs <- rs_data %>%
  count(year, name = "count") %>%
  right_join(years_all, by = "year") %>%
  replace_na(list(count = 0)) %>%
  mutate(type = "Remote Sensing")

years_field <- field_data %>%
  count(year, name = "count") %>%
  right_join(years_all, by = "year") %>%
  replace_na(list(count = 0)) %>%
  mutate(type = "Field") 

years_rs_field <- bind_rows(years_rs, years_field) %>%
  filter(year <= 2023)

ggplot(years_rs_field, aes(x = year, y = count, color = type)) +
  geom_line() +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  scale_x_continuous(breaks = seq(1970, max(years_rs_field$year), by = 10)) +
  labs(title = "Remote Sensing & Field Papers Published per Year",
       x = "Year",
       y = "Number of Studies Published", 
       color = "Primary Research Method") +
  theme_minimal()

```

## Bioclim Results
````{r biome results}
#List biomes
table(field_rs_data$biome_name)
```

```{r clim results}
#Combine control and study data
clim_ctrl_data$group <- "control"
field_rs_data$group <- field_rs_data$study_method
field_rs_data$group <- gsub(" & forecast model", "", field_rs_data$group)


clim_combined_pts <- rbind(
  field_rs_data[,c("wc2.1_30s_bio_1", "wc2.1_30s_bio_12", "group")],
  clim_ctrl_data[, c("wc2.1_30s_bio_1", "wc2.1_30s_bio_12", "group")]
)

#Generate climograph(temp v precip) scatterplot of study points and control points

ggplot(clim_combined_pts, aes(x = wc2.1_30s_bio_1, y = wc2.1_30s_bio_12, color = group)) +
  geom_point(data = subset(clim_combined_pts, group == "control"), color = "grey", size = 1, alpha = 0.5) +
  geom_point(data = subset(clim_combined_pts, group != "control"), size = 2) +
  labs(title = "Annual Temperature vs Precipitation",
       x = "Average Annual Temperature (Â°C)",
       y = "Average Annual Precipitation (mm)",
       caption = "Each dot represents a study or a control point (grey)") +
  scale_color_manual(values = c("field" = "red", "remote sensing" = "blue", "remote sensing & field" = "purple", "control" = "grey")) +
  theme(legend.position = "right")

# plot annual temperature vs average rainfall for my papers
# have field and remote sensing in two different colours
# compare that against 1000+ random points from the globe as grey points
#climograph spatSample in TERRA

```

## Quick Field Stats
```{r quick field stats}

table(field_data$bio.exp)
table(field_data$structural)
table(field_data$slip_driver)

# NUMBER OF SLIPS
table(field_data$slip_number)
field_data <- field_data %>%
  mutate(slip_number = str_replace(slip_number, "MISSING", "NA"))

field_data$slip_number <- as.numeric(field_data$slip_number)

summary(field_data$slip_number)

ggplot(field_data, aes(x = slip_number)) +
  geom_histogram(fill = "blue", color = "black", na.rm = TRUE) +
  labs(title = "Landslides Surveyed in Field Studies",
       x = "# Landslides Surveyed",
       y = "Studies") +
  theme_minimal()

# EXOTIC
field_data <- field_data %>%
  mutate(exotic = ifelse(grepl("TRUE", exotic, ignore.case = TRUE), "TRUE", FALSE))
table(field_data$exotic)

# TIME
table(field_data$time)
time_split <- field_data %>%
  mutate(time = str_replace(time, "TRUE - ", "")) %>%
  separate_rows(time, sep = ", ")
table(time_split$time)


#SEEDS
field_seeds <- table(field_data$seeds)
print(field_seeds)

```


## Remote Sensing Results
```{r rs spatial & temporal plot}
#Clean study extent (km2)
rs_data$study_scale <- suppressWarnings(as.numeric(rs_data$study_scale))

#Clean temporal scale (year range of imagery)
rs_data$year_start <- suppressWarnings(as.numeric(rs_data$year_start))
rs_data$year_end <- suppressWarnings(as.numeric(rs_data$year_end))

rs_data <- rs_data %>%
  mutate(year_range = year_end - year_start)

#Plot spatial v temporal scale

ggplot(rs_data, aes(x = study_scale, y = year_range)) +
  geom_point(size = 2) +
  labs(title = "Temporal & Spatial Scale of Remote Sensing Research",
       x = "Study extent (km2)",
       y = "Temporal scale (year range)") +
  theme_minimal() +
  #scale_x_break(c(50000, 100000)) +
  scale_x_continuous(trans='sqrt') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis text labels

#HEXBIN plot or log transform the x axis
# the spatial and temporal domains of modern ecology reference

```

````{r rs general stats}
#Imagery

#table(rs_data$imagery)

imagery_names <- c("landsat", "spot", "modis", "sentinel", "worldview", "aerial",
                   "rapideye", "planet", "photo", "quickbird", "lidar", "proba", 
                   "formosat", "irs-liss-ii", "hj-1")


imagery_counts <- map_dbl(imagery_names, function(name) {
  sum(str_detect(rs_data$imagery, fixed(name, ignore_case = TRUE)))
})

imagery_summary <- setNames(imagery_counts, imagery_names)

print(imagery_summary)

# Time range


summary(rs_data$year_range)



#Quantified Results


#Property Interactions


#Models


#Ground Truthing


```


